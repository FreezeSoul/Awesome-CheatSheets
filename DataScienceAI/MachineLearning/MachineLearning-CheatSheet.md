[![返回目录](https://parg.co/UCb)](https://github.com/wxyyxc1992/Awesome-CheatSheet) 
 
 
# 机器学习概念速览

![](http://blogs.sas.com/content/subconsciousmusings/files/2017/04/machine-learning-cheet-sheet.png)

![](http://api.ning.com/files/4*70048ZsE4d4vAJg-aTE95xugJ5lTBq5r9WVsZ54EvqkwPajzn6AeprtzImBldqq*dbze8ZGDtuyoeewh4MamSwpz8EHC5Q/Capture.PNG)

判别式模型（Discriminative Model ）是直接对条件概率 p(y|x;θ) 建模。常见的判别式模型有 线性回归模型、线性判别分析、支持向量机 SVM、神经网络等。　　生成式模型（Generative Model ）则会对 x 和 y 的联合分布 p(x,y) 建模，然后通过贝叶斯公式来求得 p(yi|x)，然后选取使得 p(yi|x) 最大的 yi，即：

简单来讲，前者不依赖于数据，能精确的解决问题；后者依赖于数据，目的是找到一个可接受的解。

经典排序或者搜索算法中的快排、堆排、二叉、B 树等等，它们的存在价值不依赖于输入数据 —— 有固定的步骤和解法，对于不同的输入数据都能正常运行（可能对特殊的数据有时候性能会差一些）；但是机器学习算法不同，你使用一个算法，做了一个模型，只是为了解决某个特定数据集下的某个需求；换一个数据和场合，这一套东西很可能就没有存在的意义了。

第一个 community，是把机器学习看作人工智能分支的一个群体，这群人的主体是计算机科学家。现在的「机器学习研究者」可能很少有人读过 1983 年出的「Machine Learning: An Artificial Intelligence Approach 」这本书。这本书的出版标志着机器学习成为人工智能中一个独立的领域。它其实是一部集早期机器学习研究之大成的文集，收罗了若干先贤（例 如 Herbert Simon，那位把诺贝尔奖、图灵奖以及各种各样和他相关的奖几乎拿遍了的科学天才）的大作，主编是 Ryszard S. Michalski（此君已去世多年了，他可算是机器学习的奠基人之一）、 Jaime G. Carbonell（此君曾是 Springer 的 LNAI 的总编）、 Tom Mitchell（此君是 CMU 机器学习系首任系主任、著名教材的作者，机器学习界没人不知道他吧）。 Machine Learning 杂志的创刊，正是这群人努力的结果。这本书值得一读。虽然技术手段早就日新月异了，但有一些深刻的思想现在并没有过时。各个学科领域总有不少东西，换了新装之后又粉墨登场，现在热火朝天的 transfer learning，其实就是 learning by analogy 的升级版。

人工智能的研究从以「推理」为重点到以「知识」为重点，再到以「学习」为重点，是有一条自然、清晰的脉络。人工智能出身的机器学习研究者，绝大部分 是把机器学习作为实现人工智能的一个途径，正如 1983 年的书名那样。他们关注的是人工智能中的问题，希望以机器学习为手段，但具体采用什么样的学习手段，是基于统计的、代数的、还是逻辑的、几何的，他们并不 care。这群人可能对统计学习目前 dominating 的地位未必满意。靠统计学习是不可能解决人工智能中大部分问题的，如果统计学习压制了对其他手段的研究，可能不是好事。这群人往往也不 care 在文章里 show 自己的数学水平，甚至可能是以简化表达自己的思想为荣。人工智能问题不是数学问题，甚至未必是依靠数学能够解决的问题。人工智能中许多事情的难处，往往在于我们不知道困难的本质在哪里，不知道「问题」在哪里。一旦「问题」清楚了，解决起来可能并不困难。

第二个 community，是把机器学习看作「应用统计学」的一个群体，这群人的主体是统计学家。和纯数学相比，统计学不太「干净」，不少数学家甚至拒绝承认统计学是数学。但如果和人工智能相比，统计学就太干净了，统计学研究的问题是清楚的，不象人工智能那样，连问题到底在哪里都不知道。在相当长时间里，统计学家和机器学习一直保持着距离。慢慢地，不少统计学家逐渐意识到，统计学本来就该面向应用，而机器学习天生就是一个很好的切入点。因为机器学习虽然用到各种各样的数学，但要分析大量数据中蕴涵的规律，统计学是必不可少的。统计学出身的机器学习研究者，绝大部分是把机器学习当作应用统计学。他们关注的是如何把统计学中的理论和方法变成可以在计算机上有效实现的算法，至于这样的算法对人工智能中的什么问题有用，他们并不 care。

这群人可能对人工智能毫无兴趣，在他们眼中，机器学习就是统计学习，是统计学比较偏向应用的一个分支，充其量是统计学与计算机科学的交叉。这群人对统计学习之外的学习手段往往是排斥的，这很自然，基于代数的、逻辑的、几何的学习，很难纳入统计学的范畴。

两个群体的文化和价值观完全不同。第一个群体认为好的工作，对于第二个群体而言可能觉得没有技术含量，但第一个群体可能恰恰认为，简单的才好，正因为很好地抓住了问题本质，所以问题变得容易解决。第二个群体欣赏的工作，第一个群体可能觉得是故弄玄虚，看不出他想解决什么人工智能问题，根本就不是在搞人工智 能、搞计算机，但别人本来也没说自己是在「搞人工智能」、「搞计算机」，本来就不是在为人工智能做研究。两个群体各有其存在的意义，应该宽容一点，不需要去互较什么短长。但是既然顶着 Machine Learning 这个帽子的不是「一伙儿」，而是「两伙儿」，那么要「跟进」的新人就要谨慎了，先搞清楚自己更喜欢「哪伙儿」。

* 加强概率与统计的基础课程，建议采用莫里斯 · 德格鲁特 (Morris H.DeGroot) 和马克 · 舍维什 (Mark J.Schervish) 合著的第四版《概率论与数理统计》(Probability and Statistics) 为教材。
* 在线性代数课程里，加强矩阵分析的内容。教材建议使用吉尔伯特 · 斯特朗 (Gilbert Strang) 的《线性代数导论》(Introduction to Linear Algebra) 。吉尔伯特 · 斯特朗在麻省理工学院一直讲述线性代数，他的网上视频课程堪称经典。后续建议开设矩阵计算，采用特雷费森 · 劳埃德 (Trefethen N.Lloyd) 和戴维 · 鲍 (David Bau lll) 著作的《数值线性代数》(Numerical Linear Algebra) 为教科书。
* 开设机器学习课程。机器学习有许多经典的书籍，但大多不太适宜做本科生的教材。最近，麻省理工学院出版的约翰 · 凯莱赫 (John D.Kelleher) 和布瑞恩 · 麦克 · 纳米 (Brian Mac Namee) 等人著作的《机器学习基础之预测数据分析》(Fundamentals of Machine Learning for Predictive Data Analytics ) ，或者安得烈 · 韦伯 (Andrew R.Webb) 和基思 · 科普塞 (Keith D.Copsey) 合著的第三版《统计模式识别》(Statistical Pattern Recognition ) 比较适合作为本科生的教科书。同时建议课程设置实践环节，让学生尝试将机器学习方法应用到某些特定问题中。
* 开设数值优化课程，建议参考教材乔治 · 诺塞达尔 (Jorge Nocedal) 和史蒂芬 · 赖特 (Stephen J.Wright) 的第二版《数值优化》(Numerical Optimization ) ，或者开设数值分析，建议采用蒂莫西 · 索尔的《数值分析》(Numerical Analysis) 为教材。
* 加强算法课程，增加高级算法，比如随机算法，参考教材是迈克尔 · 米曾马克 (Michael Mitzenmacher) 和伊莱 · 阿普法 (Eli Upfal) 的《概率与计算： 随机算法与概率分析》(Probability and Computing: Randomized Algorithms and Probabilistic Analysis) 。
* 在程序设计方面，增加或加强并行计算的内容。特别是在深度学习技术的执行中，通常需要 GPU 加速，可以使用戴维 · 柯克 (David B.Kirk) 和胡文美 (Wen-mei W.Hwu) 的教材 《大规模并行处理器编程实战》（第二版）(Programming Massively Parallel Processors:A Hands-on Approach,Second Edition ) ；另外，还可以参考优达学城 (Udacity) 上英伟达 (Nvidia) 讲解 CUDA 计算的公开课。

# 模型评估与正则化

机器学习的算法或者模型的分类有很多种，其中有一种分法把模型分为 Discriminative Modeling （判别模型）和 Generative Modeling （生成模型）两种。为了写起来方便我们以下简称 DM 和 GM 。在一个基本的机器学习问题中，我们通常有输入 $x \in X$和输出 $y \in Y$两个部分，简单地来说，DM 关注于 $x$和 $y$的关系，或者说在给定某个 $x$的情况下所对应的 $y$应该满足的规律或分布，即评估对象是最大化条件概率$p(y|x)$并直接对其建模；而 GM 则试图描述 $x$和 $y$的联合分布，即模型评估对象是最大化联合概率$p(x,y)$并对其建模。
   其实两者的评估目标都是要得到最终的类别标签$Y$， 而$Y=argmax p(y|x)$，不同的是判别式模型直接通过解在满足训练样本分布下的最优化问题得到模型参数，主要用到拉格朗日乘算法、梯度下降法，常见的判别式模型如最大熵模型、CRF、LR、SVM等；
   而生成式模型先经过贝叶斯转换成$Y = argmax p(y|x) = argmax p(x|y)*p(y)$，然后分别学习$p(y)$和$p(x|y)$的概率分布，主要通过极大似然估计的方法学习参数，如NGram、HMM、Naive Bayes。
    比较而言，判别式模型会更加灵活，而生成式模型一般需要将特征加入马尔科夫链。但是判别式模型需要有指导训练，而生成式模型可以无指导训练。

给定某系统的若干样本，求取该系统的参数，主要分为频率学派与贝叶斯学派。
#### 频率学派
假定参数是某个或者某些未知的定值，求这些参数如何取值，能够使得某目标函数取得极大或者极小值，典型的代表有矩估计、MLE、MaxEnt以及EM。
#### 贝叶斯学派
基于贝叶斯模型，假设参数本身是变化的，服从某个分布。求在这个分布约束下使得某目标函数极大/极小。
大数据下是频率学派对于贝叶斯学派的一次有效逆袭。

# Classification: 分类

```
                      Condition: A             Not A

  Test says “A”       True positive (TP)   |   False positive (FP)
                      ----------------------------------
  Test says “Not A”   False negative (FN)  |    True negative (TN)
```

* TP-- 将正类预测为正类数；
* FN-- 将正类预测为负类数；
* FP-- 将负类预测为正类数；
* TN-- 将负类预测为负类数；

* 准确率（Precision ， $P$）定义为被正确预测为正例的数目占所有被预测为正例的数目的比重： $$ P = \frac{T_p}{T_p + F_p} $$
* 召回率（Recall ， $R$）定义为被正确预测为正例的数目占所有实际正例数目的比重： $$ R = \frac{T_p}{T_p + F_n} $$
* F1 则是相对综合的评价值，定义为了准确率与召回率的调和平均数： $$ F1 = 2 \frac{P \* R}{P + R} $$


当量化算法的好坏时，首先需要看以下几个指标：
- True Positives(TP)：即实际为正例且被分类器划分为正例的样本数；
- False Positives(FP)：即实际为负例但被分类器划分为正例的样本数；
- True Negatives(TN)：即实际为负例且被分类器划分为负例的样本数；
- False Negatives(FN)：即实际为负例但被分类器划分为负例的样本数；

一般进行评价时，有两个指标：
（1）准确率
$$
accuracy = \frac{TP+TN}{P+N}
$$
就是被分队的样本除以所有的样本数，通常来说，准确率越高，分类器越好。
（2）召回率
$$
recall = \frac{TP}{TP+FN}
$$
召回率是覆盖面的度量，度量有多少个正例被分为正例。

## Regression: 回归模型

$$
\begin{align*}
& h_{\theta}(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 \\
& h_{\theta}(x) = \sum_{i=0}^n \theta_i x_i = \theta^Tx
\end{align*}
$$
