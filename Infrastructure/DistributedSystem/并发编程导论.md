# 并发编程

随着硬件性能的迅猛发展与大数据时代的来临，并发编程日益成为编程中不可忽略的重要组成部分。简单定义来看，如果执行单元的逻辑控制流在时间上重叠，那它们就是并发(Concurrent)的。并发编程复兴的主要驱动力来自于所谓的“多核危机”。正如摩尔定律所预言的那样，芯片性能仍在不断提高，但相比加快 CPU 的速度，计算机正在向多核化方向发展。正如 Herb Sutter 所说，“免费午餐的时代已然终结”。为了让代码运行得更快，单纯依靠更快的硬件已无法满足要求，我们需要利用多核，也就是发掘并行执行的潜力。在任何一个讨论并发编程的地方，都要首先讨论下并发与并行的区别，首先引用下 Rob Pike 的经典描述：

> 并发是同一时间应对(dealing with)多件事情的能力；并行是同一时间动手做(doing)多件事情的能力。

并发(Concurrency) 不等于并⾏(Parallelism)并发是指程序的逻辑结构；并⾏是指程序的运⾏状态；并⾏依赖硬件支持(多核)。并发是并⾏的必要条件；但并发不是并⾏的充分条件。并发只是更符合现实问题本质的表达，目的是简化代码逻辑，⽽不是使程序运⾏更快。要是程序运⾏更快必是并发程序+多核并⾏。并发是问题域中的概念——程序需要被设计成能够处理多个同时(或者几乎同时)发生的事件；一个并发程序含有多个逻辑上的独立执行块，它们可以独立地并行执行，也可以串行执行。而并行则是方法域中的概念——通过将问题中的多个部分并行执行，来加速解决问题。一个并行程序解决问题的速度往往比一个串行程序快得多，因为其可以同时执行整个任务的多个部分。并行程序可能有多个独立执行块，也可能仅有一个。
具体而言，Redis 会是一个很好地区分并发和并行的例子。Redis 本身是一个单线程的数据库，但是可以通过多路复用与事件循环的方式来提供并发地 I/O 服务。这是因为多核并行本质上会有很大的一个同步的代价，特别是在锁或者信号量的情况下。因此，Redis 利用了单线程的事件循环来保证一系列的原子操作，从而保证了即使在高并发的情况下也能达到几乎零消耗的同步。再引用下 Rob Pike 的描述：

> A single-threaded program can definitely provides concurrency at the I/O level by using an I/O (de)multiplexing mechanism and an event loop (which is what Redis does).

最后总结而言，在笔者的并发编程实战系列文章中，我会关注如下几个方面:
(1)并发单元:Concurrent Primitive
(2)并发控制:Concurrency Control
(3)异步模式:Asynchronous Pattern
(4)并发模型:Concurrent Model
(5)并发 IO:Concurrent IO

## 并发的魅力

从计算机系统本身而言，并发被看做是操作系统内核用来运行多个应用程序的机制。很久很久以前是没有并发这个概念的，因为那个时候操作系统并不支持多任务。现在的操作系统今非昔比，支持抢占式任务、多线程、分页、TCP/IP 等现代操作系统特性，能满足用户各种各样的需求同时响应用户的不同操作，靠的是多任务系统的支持。在 Unix 时代一个进程(执行中的程序)只有一个线程，现代操作系统允许一个进程有多条线程。每个线程有独立栈空间、寄存器、程序计数器(存放下一条执行指令)。操作系统调度程序调度的是线程(在本文中提到线程的地方都指的是操作系统级的线程)，并非进程，也就是说线程才是调度的基本单位。 在单处理器系统中，一个处于运行状态的 IO 消耗型程序，例如一个网络读取阻塞或用户输入阻塞导致处理器出现空闲，在视处理器为昂贵资源的情形下，这是巨大的浪费。然后，在对称处理器中(SMP)，因为只有一个线程，那它只能在其中一个处理器上运行，也就是说剩余的处理器被白白浪费。如果使用多线程，不仅能充分利用多处理器，还能通过线程并发解决上述 IO 消耗程序中处理器空闲问题。并发编程能够解决的典型问题如下所示：

```
while (true){
     request = next_http_request()
     request_work(request)
}
```

当 request_work 发起 I/O 之后 CPU 是完全空闲下来的，而可怜的新请求(next_http_request)必须等待 I/O 完成之后才可以获取 CPU 的控制权。所以 CPU 的利用率非常低，并发要解决的问题就是提高 CPU 的利用率。明白这一点我们也就清楚了，并发只对非 CPU 密集型程序管用，如果 CPU 利用率非常高，更多的并发只会让情况更加糟糕。并发虽好，也不能滥用啊，典型的并发编程的适用场景包括:

- 在多处理器上进行并行计算：在只有一个 CPU 的单处理器上, 井发流是交替的。在任何时间点上, 都只有一个流在 CPU 上实际执行。 然而, 那些有多个 CPU 的机器, 称为多处理器, 可以真正地同时执行多个流。被分成并发流的并发应用 在这样的机器上能够运行得快很多，这对大规模数据库和科学应用尤为重要。
- 访问慢速 IO 设备：当一个应用正在等待来自慢速 IO 设备 (例如磁盘) 的数据到达时，内核会运行其他进程使 CPU 保持繁忙。 每个应用都可以以类似的方式，通过交替执行 I/O，请求和其他有用的工作来使用并发性。

0 与人交互。 和计算机交互的人要求计算机同时执行多个任务的能力。 例如, 他们在打印“
个文档时, 可能想要调整一个窗口的大伽 现代视窗系统利用并发性来提供这种能九 每
次用户请求某种操作 忧匕如说通过单击鼠标) 时, 一个独立的并发逻辑流被创建来执行这
个操作。

0 通过推迟工作以减少执行时胤 有时, 应用程序能够通过推迟其他操作井同时执行它们,
利用并发性来降低某些操作的延遮 比如, ˉ 一个动态存储分配器可以通过椎迟与酬个运行
在较低优先级上的并发 “合井” 流的合并 (coalescing), 使用空闲时的 CPU 周期, 来降低
单个 free 操作的延迟。

0 服务多个网络客户撇 我们在第 12 章中学习的迭代 (iterative) 网络服务器是不现实胞 因
为它们一次只能为一个客户端提供服叙 因此, 一个慢速的客户端可能会导致服务器拒绝
为所有其他客户端服务。 对于闻个真正的服务器来说 可能期望它每秒为成百上千的客户
端提供服务, ′′个慢速客户端寻致拒绝为其他客户端服务, 这是不能接受峋 一个更好的
方法是创建一个并发服务糕 它为每个客户端创建各自独立的逻辑流 这就允许服务器同
时为多个客户端服务, 并且这也避免了慢速客户端独占服务器。

## 并发编程与分布式系统

## Concurrent Primitive:并发执行单元

# Parallelism:并行架构

人们通常认为并行等同于多核，但现代计算机在不同层次上都使用了并行技术。比如说，单核的运行速度现今仍能每年不断提升的原因是：单核包含的晶体管数量，如同摩尔定律预测的那 样变得越来越多，而单核在位级和指令级两个层次上都能够并行地使用这些晶体管资源。

## Bit-Level:位级并行

为什么 32 位计算机比 8 位计算机运行速度更快？因为并行。对于两个 32 位数的加法，8 位计算机必须进行多次 8 位计算，而 32 位计算机可以一步完成，即并行地处理 32 位数的 4 字节。计算机的发展经历了 8 位、16 位、32 位，现在正处于 64 位时代。然而由位升级带来的性能改善是存在瓶颈的，这也正是短期内我们无法步入 128 位时代的原因。

## SIMD-Level:单指令、多数据并行

在最低的层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即 SIMD 并行。例如，较新的 Intel 和 AMD 处理器都具有并行地对 4 对单精度浮点数(float)做加法的指令。提供这些 SIMD 指令多是为了提高处理影像、声音和视频数据应用的执行速度。虽然有些编译器试图从 C 程序中自动抽取出 SIDM 并行性，但是更可靠的方法是使用编译器支持的特殊向量数据类型来写程序，譬如 GCC 就支持向量数据类型。

## Instruction-Level:指令级并行

在较低的抽象层次上，现代处理器

## Task-Level:任务级并行

# Process:基于进程的并发

# Thread:基于线程的并发

# Coroutine:基于协程的并发

- [谈谈协程](http://mp.weixin.qq.com/s/966vBRDHNY0taIWEseQo6w)

任务、作业(Job，Task，Schedule)

在进程的概念出现之前，进程有着这样的称谓。

进程

为了使多个程序能够并发(同一时刻只有一个在运行，但感觉起来像多个同时运行；并行(同一时刻真的多个在运行，不是感觉像多个))的执行，操作系统需要一个结构来抽象和表示这个程序的运行。

进程是操作系统对一个正在运行的程序的一种抽象结构。
进程是指在操作系统中能独立运行并作为资源分配的基本单位，由一组机器指令、数据和堆栈等组成的能独立运行的活动实体。
操作系统可以同时运行多个进程，多个进程直接可以并发执行和交换信息。
进程在运行是需要一定的资源，如 CPU、存储空间和 I/O 设备等。
线程

进程是资源分配的基本单位，进程的调度涉及到的内容比较多(存储空间，CPU，I/O 资源等，进程现场保护)，调度开销较大，在并发的切换过程效率较低。为了更高效的进行调度，提出了比进程更轻量的独立运行和调度的基本单位。

线程比进程更轻量
线程能独立运行，独立调度，拥有资源(一般是 CPU 资源，程序计数器等)
线程调度能大幅度减小调度的成本(相对于进程来说)，线程的切换不会引起进程的切换
线程的引入进一步提高了操作系统的并发性，线程能并发执行
同一个进程的多个线程共享进程的资源(省去了资源调度现场保护的很多工作)
协程、共行程序、Coroutine

协程是用户模式下的轻量级线程，操作系统内核对协程一无所知
协程的调度完全有应用程序来控制，操作系统不管这部分的调度
一个线程可以包含一个或多个协程
协程拥有自己的寄存器上下文和栈，协程调度切换时，将寄存器上细纹和栈保存起来，在切换回来时恢复先前保运的寄存上下文和栈
协程能保留上一次调用时的状态，看到这里各种生成器(生成器是被阉割的协程)的概念浮现出来了。。
Windows 下的实现叫纤程
纤程

代码易移植性一直是平台间交互考虑的重点，在将引用程序从 Unix 移植到 Windows 的过程中，会存在一些类似于线程栈管理的不一致、结构和异常处理等问题，增加移植难度和成本。

为了帮助各公司更快、更正确地将他们的代码移植到 Windows，Microsoft 在操作系统中增加了纤程(Fiber)。纤程与纤程对比，有如下的特性：

线程是在 Windows 内核中实现的，操作系统会根据系统的调度算法对纤程程进行调度。
纤程是在用户模式下实现的，内核对纤程一无所知。
纤程是更轻量级的线程，一个线程可以包含一个或多个纤程
内核会对纤程进行抢占式调度，线程一次只能执行一个纤程的代码(具体执行哪一个纤程由用户调度算法决定)
纤程的调度与线程的调度没有直接关系，操作系统随时可能会夺取纤程所在线程的运行权
除非正在运行的纤程显式的切换到另一个纤程，否则其他纤程将无法运行
Windows 有一套 API 来讲线程转换为纤程或者在同一个线程里面创建多个纤程
管程

把管程放最后还加了一道分割线原因是管程跟上面的几个概念不是同一类东东，虽然长得很像，就像 Car 和 Bar 一样。

临界资源的概念：

一次只允许一个进程访问的资源
多个进程只能互斥访问的资源
临界资源的访问需要同步操作，比如信号量就是一种方便有效的进程同步机制。但信号量的方式要求每个访问临界资源的进程都具有 wait 和 signal 操作。这样使大量的同步操作分散在各个进程中，不仅给系统管理带来了麻烦，而且会因同步操作的使用不当导致死锁。管程就是为了解决这样的问题而产生的。

操作系统中管理的各种软件和硬件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对该资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。利用共享数据结构抽象地表示系统中的共享资源。而把对该共享数据结构实施的操作定义为一组过程，如资源的请求和释放过程 request 和 release。进程对共享资源的申请、释放和其他操作，都是通过这组过程对共享数据结构的操作来实现的，这组过程还可以根据资源的情况接受或阻塞进程的访问，确保每次仅有一个进程使用该共享资源，这样就可以统一管理对共享资源的所有访问，实现临界资源互斥访问。

管程就是代表共享资源的数据结构以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序共同构成的一个操作系统的资源管理模块。管程被请求和释放临界资源的进程所调用。

管程定义了一个数据结构和能为并发进程所执行(在该数据结构上)的一组操作，这组操作能同步进程和改变管程中的数据。

超线程

这个也是一个跟上面的概念不是一类事的概念，超线程是 Intel CPU 设计上的一种技术。

一个 CPU 物理核在同一时间只能执行一个线程，而线程的切换会消耗掉上万的始终周期，效率还不够高。超线程就是在实现同一个 CPU 物理核在同一时间能几乎执行两个线程的技术。这就是我们在 Intel CPU 的机子上的任务管理器中经常看到 double 的 CPU 物理核心的缘由。
