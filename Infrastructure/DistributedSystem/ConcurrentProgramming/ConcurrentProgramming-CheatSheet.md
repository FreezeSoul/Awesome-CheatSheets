[![返回目录](https://parg.co/UCb)](https://github.com/wxyyxc1992/Awesome-CheatSheet)

# 并发编程导论

并发控制中主要考虑线程之间的通信(线程之间以何种机制来交换信息)与同步(读写等待，竞态条件等)模型，在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。

Java 就是典型的共享内存模式的通信机制，而 Go 则是提倡以消息传递方式实现内存共享，而非通过共享来实现通信。

在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。

本文参考了许多经典的文章描述/示例，统一声明在了 [Concurrent Programming Links]()。

# 并发与并行

# 并发单元

## 进程

## 线程

术语“线程”可以用来描述很多不同的事情。在本文中，我会使用它来代指一个逻辑线程。也就是：按照线性顺序的一系列操作；一个执行的逻辑路径。CPU 的每个核心只能真正并发同时执行一个逻辑线程。

CPU：独立的中央处理单元，体现在主板上是有多个 CPU 的槽位。  
CPU cores：在每一个 CPU 上，都可能有多个核（core），每一个核中都有独立的一套 ALU、FPU、Cache 等组件，所以这个概念也被称作物理核。  
processor：这个主要得益于超线程技术，可以让一个物理核模拟出多个逻辑核，即 processor。
简单来说就是，当有多个计算任务时，可以让其中一个计算任务使用 ALU 的时候，另一个则去使用 FPU。
这样就可以充分利用物理核中的各个部件，使得同一个物理核中，也可以并行处理多个计算任务。
理论上来说，对于计算密集型的任务，线程数应该和 CPU 所能提供的并行数一致。那这里的“并行数”应该采取物理核数还是 processor 数呢？“超线程”技术，并没有像理论中的那样加大并行度，从而提高吞吐量。在我的程序（以及大部分程序）中，对各个计算部件（FPU\ALU）的使用并不是均匀的，一般 ALU 的使用占大头，FPU 的使用只占小部分，所以超线程技术并不能带来很大的并行度提升；而这一点点提升，也被线程切换带来的消耗所抵消了。

算术逻辑单元 ALU 与浮点运算单元 FPU

如果线程的数量多于内核的数量，那么有的线程必须要暂停以便于其他的线程来运行工作，当再次轮到自己的执行的时候，会将任务恢复。为了支持暂停和恢复，线程至少需要如下两件事情：
某种类型的指令指针。也就是，当我暂停的时候，我正在执行哪行代码？
一个栈。

此处的线程，即指操作系统线程

系统在将线程调度到 CPU 上时就有了足够的信息，能够暂停某个线程、允许其他的线程运行，随后再次恢复原来的线程。这种操作通常对线程来说是完全透明的。从线程的角度来说，它是连续运行的。

操作系统实现的线程有两个属性，这两个属性极大地限制了它们可以存在的数量；任何将语言线程和操作系统线程进行 1:1 映射的解决方案都无法支持大规模的并发。

使用操作系统线程将会导致每个线程都有固定的、较大的内存成本
采用操作系统线程的另一个主要问题是每个 OS 线程都有大小固定的栈。尽管这个大小是可以配置的，但是在 64 位的环境中，JVM 会为每个线程分配 1M 的栈。你可以将默认的栈空间设置地更小一些，但是你需要权衡内存的使用，因为这会增加栈溢出的风险。代码中的递归越多，就越有可能出现栈溢出。如果你保持默认值的话，那么 1000 个线程就将使用 1GB 的 RAM。虽然现在 RAM 便宜了很多，但是几乎没有人会为了运行上百万个线程而准备 TB 级别的 RAM。

操作系统线程的另一个瓶颈就是上下文切换的代价较大，从该角度来说，使用操作系统线程只能有数万个线程。操作系统有一个所有正在运行的进程和线程的列表，并试图为它们分配“公平”的 CPU 运行时间 [5]。当内核从一个线程切换至另一个线程时，有很多的工作要做。操作系统有一个所有正在运行的进程和线程的列表，并试图为它们分配“公平”的 CPU 运行时间 [5]。当内核从一个线程切换至另一个线程时，有很多的工作要做。

## Coroutine | 协程

“用户空间线程（user space thread）”来代指由语言进行调度的线程，而不是内核 /OS 所调度的线程。

Go 的栈是动态分配大小的，随着存储数据的数量而增长和收缩。

每个新建的 Goroutine 只有大约 4KB 的栈。每个栈只有 4KB，那么在一个 1GB 的 RAM 上，我们就可以有 256 万个 Goroutine 了，相对于 Java 中每个线程的 1MB，这是巨大的提升。Golang 实现了自己的调度器，允许众多的 Goroutines 运行在相同的 OS 线程上。就算 Go 会运行与内核相同的上下文切换，但是它能够避免切换至 ring-0 以运行内核，然后再切换回来，这样就会节省大量的时间。但是，这只是纸面上的分析。为了支持上百万的 Goroutines，Go 需要完成更复杂的事情。

要支持真正的大并发需要另外一项优化：当你知道线程能够做有用的工作时，才去调度它。如果你运行大量线程的话，其实只有少量的线程会执行有用的工作。Go 通过集成通道（channel）和调度器（scheduler）来实现这一点。如果某个 Goroutine 在一个空的通道上等待，那么调度器会看到这一点并且不会运行该 Goroutine。Go 更近一步，将大多数空闲的线程都放到它的操作系统线程上。通过这种方式，活跃的 Goroutine（预期数量会少得多）会在同一个线程上调度执行，而数以百万计的大多数休眠的 Goroutine 会单独处理。这样有助于降低延迟。

除非 Java 增加语言特性，允许调度器进行观察，否则的话，是不可能支持智能调度的。但是，你可以在“用户空间”中构建运行时调度器，它能够感知线程何时能够执行工作。这构成了像 Akka 这种类型的框架的基础，它能够支持上百万的 Actor。

# 并发控制

# Concurrent IO | 并发 IO

## IO 多路复用

select，poll，epoll 都是 IO 多路复用的机制。IO 多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪(一般是读就绪或者写就绪)，能够通知程序进行相应的读写操作。但 select，poll，epoll 本质上都是同步 IO，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 IO 则无需自己负责进行读写，异步 IO 的实现会负责把数据从内核拷贝到用户空间。

select 本身是轮询式、无状态的，每次调用都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大。epoll 则是触发式处理连接，维护的描述符数目不受到限制，而且性能不会随着描述符数目的增加而下降。

| 方法   | 数量限制                                                                                            | 连接处理                                                                                                                   | 内存操作                                                                                                                  |
| ------ | --------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- |
| select | 描述符个数由内核中的 FD_SETSIZE 限制，仅为 1024；重新编译内核改变 FD_SETSIZE 的值，但是无法优化性能 | 每次调用 select 都会线性扫描所有描述符的状态，在 select 结束后，用户也要线性扫描 fd_set 数组才知道哪些描述符准备就绪(O(n)) | 每次调用 select 都要在用户空间和内核空间里进行内存复制 fd 描述符等信息                                                    |
| poll   | 使用 pollfd 结构来存储 fd，突破了 select 中描述符数目的限制                                         | 类似于 select 扫描方式                                                                                                     | 需要将 pollfd 数组拷贝到内核空间，之后依次扫描 fd 的状态，整体复杂度依然是 O(n)的，在并发量大的情况下服务器性能会快速下降 |
| epoll  | 该模式下的 Socket 对应的 fd 列表由一个数组来保存，大小不限制(默认 4k)                               | 基于内核提供的反射模式，有活跃 Socket 时，内核访问该 Socket 的 callback，不需要遍历轮询                                    | epoll 在传递内核与用户空间的消息时使用了内存共享，而不是内存拷贝，这也使得 epoll 的效率比 poll 和 select 更高             |

## 事件驱动架构(Event-Driven Architecture)

Redis 的事件模型实现基于 linux 的 epoll，sun 的 export,FreeBSD 和 Mac osx 的 queue，还有 select

如果你确实需要知道,系统将在何时达到一致的状态?你可能需要一种算法,来应用到这个状态上,不过,仅仅在它达到一个与后续请求相关的一致状态时才会被应用.
继 续讨论前面的例子,如果在资产到达时,需要通知用户,怎么办? 在将资产交付给接收用户的那个事务内创建一个事件,就可以提供一种机制,当达到一个事先确定的状态时,可以做进一步的处理.EDA(事件驱动架 构,Event-Driven Architecture)可以显著改善可伸缩性以及架构的解耦。

基于事件驱动的服务器，无需为每一个请求创建额外的对应线程，虽然可以省去创建线程与销毁线程的开销，但它在处理网络请求时，会把侦听到的请求放在事件队列中交给观察者，事件循环会不停的处理这些网络请求。

典型的后端服务可以分为跟业务无关的通信层，以及业务逻辑层；通信层负责 socket 连接的创建和管理，业务逻辑层则是负责被动响应请求，或主动推送业务消息。通信层以 IO 操作为主，并发连接数非常高，但是不太消耗 CPU；对 tcp 用 epoll/iocp 等新模式，让 tcp 连接和线程进程不再强制产生绑定，操作系统只是把所有注册到 epoll 里面的 tcp 连接状态变化返回给程序，让 tcp 处理回归本质。以 Nginx 为代表的反向代理服务器，即用事件驱动的形式取代多线程。

而对于业务逻辑层而言，不但要跟内网的网络服务通信，还要跟外网的服务通信，在业务逻辑层也产生了大量的外网网络 IO，导致一个请求不能在 100ms 内完成，可能增加到了 500ms 甚至几秒钟，其中大部分时间是在等待网络，白白的占用了一个线程等 IO。第二代事件驱动模型应运而生，把业务逻辑也变成事件驱动，彻底消除浪费线程等待 IO 这个现象。事件驱动有两件常见的外衣，一件是异步回调，另一件是 coroutine，近几年有了很多应用：

- Go 的 goroutine
- Python 3 的 coroutine
- Kotlin 的 coroutine
- nodejs 的异步回调
- swoole 1 的异步回调和 swoole 2 的 coroutine
- erlang/elixir 的 process 也算是 coroutine
- VertX 的异步回调

# 锁

# CAS

为了实现可串行化，同时避免锁机制存在的各种问题，我们可以采用基于多版本并发控制（Multiversion concurrency control，MVCC）思想的无锁事务机制。人们一般把基于锁的并发控制机制称成为悲观机制，而把 MVCC 机制称为乐观机制。这是因为锁机制是一种预防性的，读会阻塞写，写也会阻塞读，当锁定粒度较大，时间较长时并发性能就不会太好；而 MVCC 是一种后验性的，读不阻塞写，写也不阻塞读，等到提交的时候才检验是否有冲突，由于没有锁，所以读写不会相互阻塞，从而大大提升了并发性能。我们可以借用源代码版本控制来理解 MVCC，每个人都可以自由地阅读和修改本地的代码，相互之间不会阻塞，只在提交的时候版本控制器会检查冲突，并提示 merge。目前，Oracle、PostgreSQL 和 MySQL 都已支持基于 MVCC 的并发机制，但具体实现各有不同。

MVCC 的一种简单实现是基于 CAS（Compare-and-swap）思想的有条件更新（Conditional Update）。普通的 update 参数只包含了一个 keyValueSet’，Conditional Update 在此基础上加上了一组更新条件 conditionSet { … data[keyx]=valuex, … }，即只有在 D 满足更新条件的情况下才将数据更新为 keyValueSet’；否则，返回错误信息。这样，L 就形成了如下图所示的 Try/Conditional Update/(Try again)的处理模式：

## MVCC

MVCC 的全称是 Multi-Version Concurrency Control，通常用于数据库等场景中，实现多版本的并发控制。MVCC 是通过保存数据的多个版本来实现并发控制，当需要更新某条数据时，实现了 MVCC 的存储系统不会立即用新数据覆盖原始数据，而是创建该条记录的一个新的版本。对于多数数据库系统，存储会分为 Data Part 和 Undo Log，Data Part 用来存储事务已提交的数据，而 Undo Log 用来存储旧版本的数据。多版本的存在允许了读和写的分离，读操作是需要读取某个版本之前的数据即可，和写操作不冲突，大大提高了性能。

在没有事务支持的情况下，多个 L 进行并发处理可能会导致数据一致性问题。比如，考虑 L1 和 L2 的如下执行顺序：

L1 从 D 读取 key:123 对应的值 100
L2 从 D 读取 key:123 对应的 100
L1 将 key:123 更新为 100 + 1
L2 将 key:123 更新为 100 + 2
如果 L1 和 L2 串行执行，key:123 对应的值将为 103，但上面并发执行中 L1 的执行效果完全被 L2 所覆盖，实际 key:123 所对应的值变成了 102。

为了让 L 的处理具有可串行化特性(Serializability)，一种最直接的解决方案就是考虑为 D 加上基于锁的简单事务。让 L 在进行业务处理前先锁定 D，完成以后释放锁。另外，为了防止持有锁的 L 由于某种原因长时间未提交事务，D 还需要具有超时机制，当 L 尝试提交一个已超时的事务时会得到一个错误响应。本方案的优点是实现简单，缺点是锁定了整个数据集，粒度太大；时间上包含了 L 的整个处理时间，跨度太长。虽然我们可以考虑把锁定粒度降低到数据项级别，按 key 进行锁定，但这又会带来其他的问题。由于更新的 keySet’可能是事先不确定的，所以可能无法在开始事务时锁定所有的 key；如果分阶段来锁定需要的 key，又可能出现死锁(Deadlock)问题。另外，按 key 锁定在有锁争用的情况下并不能解决锁定时间太长的问题。所以，按 key 锁定仍然存在重要的不足之处。
